{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d4c7b1",
   "metadata": {},
   "source": [
    "### Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e90bf5",
   "metadata": {},
   "source": [
    "### sklearn.linear_model.Linear_Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810f632",
   "metadata": {},
   "source": [
    "#### Ordinary least squares Linear Regression.\n",
    "\n",
    "LinearRegression fits a linear model with coefficients w = (w1, â€¦, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6fa94",
   "metadata": {},
   "source": [
    "#### Parameters: \n",
    "\n",
    "fit_interceptbool, default=True\n",
    "Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).\n",
    "\n",
    "normalizebool, default=False\n",
    "This parameter is ignored when fit_intercept is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use StandardScaler before calling fit on an estimator with normalize=False.\n",
    "\n",
    "Deprecated since version 1.0: normalize was deprecated in version 1.0 and will be removed in 1.2.\n",
    "\n",
    "copy_Xbool, default=True\n",
    "If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "n_jobsint, default=None\n",
    "The number of jobs to use for the computation. This will only provide speedup in case of sufficiently large problems, that is if firstly n_targets > 1 and secondly X is sparse or if positive is set to True. None means 1 unless in a joblib.parallel_backend context.\n",
    "\n",
    "positivebool, default=False\n",
    "When set to True, forces the coefficients to be positive. This option is only supported for dense arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c99cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Implementation of OLS\n",
    "\n",
    "### importing libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1,1], [2,3], [3,4], [4, 6]])\n",
    "y = np.dot(X, np.array([1,2])) + 3\n",
    "reg = LinearRegression().fit(X,y)\n",
    "reg.score(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac91aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d7a6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9999999999999964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b231a616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.array([[5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c397582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'n_jobs': None,\n",
       " 'normalize': False,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12c83a",
   "metadata": {},
   "source": [
    "### Implementing Ridge regression\n",
    "\n",
    "Linear least squares with l2 regularization\n",
    "\n",
    "Minimizes the objectives function: ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
    "\n",
    "Parameters:\n",
    "\n",
    "alpha{float, ndarray of shape (n_targets,)}, default=1.0\n",
    "Constant that multiplies the L2 term, controlling regularization strength. alpha must be a non-negative float i.e. in [0, inf).\n",
    "\n",
    "When alpha = 0, the objective is equivalent to ordinary least squares, solved by the LinearRegression object. For numerical reasons, using alpha = 0 with the Ridge object is not advised. Instead, you should use the LinearRegression object.\n",
    "\n",
    "fit_interceptbool, default=True Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).\n",
    "\n",
    "normalizebool, default=False This parameter is ignored when fit_intercept is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use StandardScaler before calling fit on an estimator with normalize=False.\n",
    "\n",
    "Deprecated since version 1.0: normalize was deprecated in version 1.0 and will be removed in 1.2.\n",
    "\n",
    "copy_Xbool, default=True If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "n_jobsint, default=None The number of jobs to use for the computation. This will only provide speedup in case of sufficiently large problems, that is if firstly n_targets > 1 and secondly X is sparse or if positive is set to True. None means 1 unless in a joblib.parallel_backend context.\n",
    "\n",
    "positivebool, default=False When set to True, forces the coefficients to be positive. This option is only supported for dense arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4815871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "ran = np.random.RandomState(0)\n",
    "\n",
    "number_Of_Samples, number_Of_Features = 10, 5\n",
    "y = ran.randn(number_Of_Samples)\n",
    "X = ran.randn(number_Of_Samples, number_Of_Features)\n",
    "\n",
    "clx = Ridge(alpha = 1.0).fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91ba9f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836781050289735"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ade9246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fee38f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183fe8a",
   "metadata": {},
   "source": [
    "### Implementing Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01e635",
   "metadata": {},
   "source": [
    "Linear Model trained with L1 prior as regularizer (aka the Lasso).\n",
    "\n",
    "The optimization objective for Lasso is:\n",
    "\n",
    "(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "368ebfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0.,  0., -0.,  0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "number_Of_Samples, number_of_features = 10, 5\n",
    "\n",
    "X = rng.randn(number_Of_Samples, number_of_features)\n",
    "y = rng.randn(number_Of_Samples)\n",
    "\n",
    "clf = Lasso(alpha = 1.0).fit(X,y)\n",
    "\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43f7ded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2427925882379088"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a55a62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.  0.  0. -0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1c70",
   "metadata": {},
   "source": [
    "### Implementing ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887edd43",
   "metadata": {},
   "source": [
    "Linear regression with combined L1 and L2 priors as regularizer.\n",
    "\n",
    "Minimizes the objective function:\n",
    "\n",
    "1 / (2 * n_samples) * ||y - Xw||^2_2\n",
    "+ alpha * l1_ratio * ||w||_1\n",
    "+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:\n",
    "\n",
    "a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
    "where:\n",
    "\n",
    "alpha = a + b and l1_ratio = a / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a9f6f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features = 2, random_state = 0)\n",
    "\n",
    "regr = ElasticNet(random_state = 0)\n",
    "\n",
    "regr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87a3e72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.83816048, 64.55968825])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97213b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8904453086976037"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f7d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4512607561654032"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7478e330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149.40879773])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(np.array([[1,2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8777010",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09e26474",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208644a5",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "\n",
    "penalty{â€˜l1â€™, â€˜l2â€™, â€˜elasticnetâ€™, â€˜noneâ€™}, default=â€™l2â€™\n",
    "Specify the norm of the penalty:\n",
    "\n",
    "'none': no penalty is added;\n",
    "\n",
    "'l2': add a L2 penalty term and it is the default choice;\n",
    "\n",
    "'l1': add a L1 penalty term;\n",
    "\n",
    "'elasticnet': both L1 and L2 penalty terms are added.\n",
    "\n",
    "l1_ratiofloat, default=None\n",
    "The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'. Setting l1_ratio=0 is equivalent to using penalty='l2', while setting l1_ratio=1 is equivalent to using penalty='l1'. For 0 < l1_ratio <1, the penalty is a combination of L1 and L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce7cdc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snigdhakakkar/opt/anaconda2/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X,y)\n",
    "\n",
    "clf.predict(X[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb260f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15fce0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41874027,  0.96699274, -2.52102832, -1.08416599],\n",
       "       [ 0.53123044, -0.31473365, -0.20002395, -0.94866082],\n",
       "       [-0.11249017, -0.65225909,  2.72105226,  2.03282681]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b461fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.81802911e-01, 1.81970751e-02, 1.43580537e-08],\n",
       "       [9.71729527e-01, 2.82704429e-02, 3.00353141e-08]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f331a",
   "metadata": {},
   "source": [
    "### Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0193435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8eacb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)\n",
    "gnr = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3225ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10662e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnr.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6acb317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of misclassified datapoints out of 45 points: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of misclassified datapoints out of %d points: %d\" %(X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e2713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
